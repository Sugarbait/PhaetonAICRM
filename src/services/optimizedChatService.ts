/**
 * Optimized Chat Service
 *
 * Enhanced version of chatService with:
 * - Intelligent pagination and caching
 * - Request deduplication
 * - Background vs foreground loading
 * - Delta updates instead of full refreshes
 * - Smart auto-refresh with change detection
 */

import { optimizedApiService } from './optimizedApiService'
import { chatService, type Chat, type ChatListOptions, type ChatListResponse } from './chatService'

interface OptimizedChatOptions extends ChatListOptions {
  priority?: 'high' | 'medium' | 'low'
  backgroundRequest?: boolean
  deltaUpdate?: boolean // Only fetch changed data
  lastUpdated?: number // Timestamp for delta updates
}

interface CachedChatData {
  chats: Chat[]
  totalCount: number
  lastUpdated: number
  filters: string // Serialized filters for cache key
  pagination_key?: string
  has_more: boolean
}

interface ChatChangeTracker {
  lastPollTime: number
  knownChatIds: Set<string>
  chatHashes: Map<string, string> // chat_id -> hash of chat data
}

export class OptimizedChatService {
  private changeTracker: ChatChangeTracker = {
    lastPollTime: 0,
    knownChatIds: new Set(),
    chatHashes: new Map()
  }

  private readonly DELTA_UPDATE_INTERVAL = 30000 // 30 seconds

  /**
   * Get chats with intelligent caching and delta updates
   */
  async getOptimizedChats(options: OptimizedChatOptions = {}): Promise<ChatListResponse> {
    const {
      priority = 'medium',
      backgroundRequest = false,
      deltaUpdate = false,
      lastUpdated,
      ...chatOptions
    } = options

    // Generate cache key based on filters
    const cacheKey = this.generateCacheKey(chatOptions)
    const shouldUseDelta = deltaUpdate && this.canUseDeltaUpdate(lastUpdated)

    console.log(`[OptimizedChatService] Getting chats with options:`, {
      priority,
      backgroundRequest,
      deltaUpdate,
      shouldUseDelta,
      cacheKey: cacheKey.substring(0, 50) + '...'
    })

    try {
      if (shouldUseDelta) {
        return await this.getDeltaUpdate(chatOptions, priority)
      } else {
        return await this.getFullChatData(chatOptions, priority, backgroundRequest)
      }
    } catch (error) {
      console.error('[OptimizedChatService] Failed to get chats:', error)
      // Fallback to original service
      return await chatService.getChatHistory(chatOptions)
    }
  }

  /**
   * Get only changed chats since last update (delta update)
   */
  private async getDeltaUpdate(
    options: ChatListOptions,
    priority: 'high' | 'medium' | 'low'
  ): Promise<ChatListResponse> {
    console.log('[OptimizedChatService] Performing delta update')

    // Get recent chats only (last 24 hours to catch any changes)
    const oneDayAgo = Math.floor((Date.now() - 24 * 60 * 60 * 1000) / 1000)

    const deltaOptions: ChatListOptions = {
      ...options,
      filter_criteria: {
        ...options.filter_criteria,
        start_timestamp: {
          gte: oneDayAgo
        }
      },
      limit: 100 // Smaller limit for delta updates
    }

    const response = await optimizedApiService.request<ChatListResponse>(
      this.buildChatApiUrl(deltaOptions),
      {
        method: 'GET',
        priority,
        cacheTTL: 30000, // Short cache for delta updates
        backgroundRequest: true
      }
    )

    // Process delta changes
    this.processDeltaChanges(response.chats)

    return response
  }

  /**
   * Get full chat data with optimized caching
   */
  private async getFullChatData(
    options: ChatListOptions,
    priority: 'high' | 'medium' | 'low',
    backgroundRequest: boolean
  ): Promise<ChatListResponse> {
    const cacheKey = this.generateCacheKey(options)

    // Try cache first for non-background requests
    if (!backgroundRequest) {
      const cached = await this.getCachedChatData(cacheKey)
      if (cached) {
        console.log('[OptimizedChatService] Using cached chat data')
        return {
          chats: cached.chats,
          pagination_key: cached.pagination_key,
          has_more: cached.has_more
        }
      }
    }

    // Fetch from API with optimizations
    const response = await optimizedApiService.request<ChatListResponse>(
      this.buildChatApiUrl(options),
      {
        method: 'GET',
        priority,
        cacheTTL: backgroundRequest ? 300000 : 120000, // Longer cache for background
        backgroundRequest,
        timeout: backgroundRequest ? 60000 : 30000
      }
    )

    // Cache the response
    await this.setCachedChatData(cacheKey, {
      chats: response.chats,
      totalCount: response.chats.length,
      lastUpdated: Date.now(),
      filters: cacheKey,
      pagination_key: response.pagination_key,
      has_more: response.has_more
    })

    // Update change tracker
    this.updateChangeTracker(response.chats)

    return response
  }

  /**
   * Intelligent auto-refresh that only updates when there are actual changes
   */
  async smartRefresh(
    currentChats: Chat[],
    options: ChatListOptions = {}
  ): Promise<{ hasChanges: boolean; chats?: Chat[]; newChats?: Chat[]; changedChats?: Chat[] }> {
    try {
      console.log('[OptimizedChatService] Starting smart refresh...')

      // For better reliability, always do a fresh fetch but with a smaller limit
      // This ensures we get the most recent data while being efficient
      const refreshOptions = {
        ...options,
        limit: Math.min(options.limit || 50, 100), // Limit to max 100 for refresh
        priority: 'medium' as const,
        backgroundRequest: true
      }

      console.log('[OptimizedChatService] Fetching fresh chat data for comparison...')
      const response = await this.getOptimizedChats(refreshOptions)

      if (!response.chats || response.chats.length === 0) {
        console.log('[OptimizedChatService] No chats returned from refresh')
        return { hasChanges: false }
      }

      // Simple but effective change detection: compare chat count and recent chat IDs
      const currentChatIds = new Set(currentChats.map(chat => chat.chat_id))

      // Check for new chats (in response but not in current)
      const newChats = response.chats.filter(chat => !currentChatIds.has(chat.chat_id))

      // Check for different chat count or new chats
      const hasNewChats = newChats.length > 0
      const countChanged = response.chats.length !== currentChats.length

      // Check if any of the recent chats have different status or content
      let hasUpdatedChats = false
      const recentResponseChats = response.chats.slice(0, 10) // Check first 10 chats

      for (const newChat of recentResponseChats) {
        const existingChat = currentChats.find(c => c.chat_id === newChat.chat_id)
        if (existingChat) {
          // Compare key fields that might change
          if (
            existingChat.chat_status !== newChat.chat_status ||
            existingChat.end_timestamp !== newChat.end_timestamp ||
            (existingChat.message_with_tool_calls?.length || 0) !== (newChat.message_with_tool_calls?.length || 0)
          ) {
            hasUpdatedChats = true
            break
          }
        }
      }

      const hasChanges = hasNewChats || countChanged || hasUpdatedChats

      if (hasChanges) {
        console.log(`[OptimizedChatService] Changes detected - new: ${newChats.length}, count changed: ${countChanged}, updates: ${hasUpdatedChats}`)
        return {
          hasChanges: true,
          chats: response.chats, // Return the fresh data
          newChats: newChats.length > 0 ? newChats : undefined
        }
      } else {
        console.log('[OptimizedChatService] No significant changes detected in smart refresh')
        return { hasChanges: false }
      }

    } catch (error) {
      console.error('[OptimizedChatService] Smart refresh failed:', error)
      // Return hasChanges: true to trigger a fallback refresh
      return { hasChanges: true }
    }
  }

  /**
   * Batch load multiple chat pages efficiently
   */
  async batchLoadChatPages(
    options: ChatListOptions,
    pageCount: number = 3
  ): Promise<Chat[]> {
    console.log(`[OptimizedChatService] Batch loading ${pageCount} pages`)

    const allChats: Chat[] = []
    const requests: Array<{ url: string; options: any }> = []

    let paginationKey: string | undefined = options.pagination_key

    // Prepare batch requests
    for (let page = 0; page < pageCount; page++) {
      const pageOptions = {
        ...options,
        pagination_key: paginationKey,
        limit: options.limit || 50
      }

      requests.push({
        url: this.buildChatApiUrl(pageOptions),
        options: {
          priority: page === 0 ? 'high' : 'medium', // First page high priority
          cacheTTL: 120000,
          backgroundRequest: page > 0 // Background for non-first pages
        }
      })

      // Note: In a real implementation, we'd need to handle pagination properly
      // This is a simplified version
      paginationKey = undefined // Reset for demo
    }

    // Execute batch requests
    const results = await optimizedApiService.batchRequests<ChatListResponse>(requests, {
      maxConcurrency: 3,
      delayBetweenBatches: 100,
      priority: 'medium'
    })

    // Process results
    results.forEach((result, index) => {
      if (result instanceof Error) {
        console.warn(`Batch page ${index} failed:`, result)
        return
      }

      const response = result as ChatListResponse
      allChats.push(...response.chats)
    })

    console.log(`[OptimizedChatService] Batch loaded ${allChats.length} chats from ${pageCount} pages`)
    return allChats
  }

  /**
   * Cancel all ongoing operations
   */
  cancelAllOperations(): void {
    optimizedApiService.cancelAllRequests()
  }

  /**
   * Clear all caches
   */
  clearAllCaches(): void {
    optimizedApiService.clearCache('chat')
    this.changeTracker = {
      lastPollTime: 0,
      knownChatIds: new Set(),
      chatHashes: new Map()
    }
  }

  /**
   * Get service statistics
   */
  getServiceStats() {
    const apiStats = optimizedApiService.getStats()
    return {
      ...apiStats,
      changeTracker: {
        knownChats: this.changeTracker.knownChatIds.size,
        lastPollTime: this.changeTracker.lastPollTime,
        trackedHashes: this.changeTracker.chatHashes.size
      }
    }
  }

  // Private helper methods

  private generateCacheKey(options: ChatListOptions): string {
    const keyData = {
      filters: options.filter_criteria || {},
      sort: options.sort_order || 'descending',
      limit: options.limit || 50,
      pagination: options.pagination_key || ''
    }
    return `chats_${btoa(JSON.stringify(keyData))}`
  }

  private canUseDeltaUpdate(lastUpdated?: number): boolean {
    if (!lastUpdated) return false

    const timeSinceUpdate = Date.now() - lastUpdated
    return timeSinceUpdate < this.DELTA_UPDATE_INTERVAL &&
           this.changeTracker.lastPollTime > 0
  }

  private buildChatApiUrl(options: ChatListOptions): string {
    const baseUrl = 'https://api.retellai.com/list-chat'
    const params = new URLSearchParams()

    if (options.limit) params.append('limit', options.limit.toString())
    if (options.pagination_key) params.append('pagination_key', options.pagination_key)
    if (options.sort_order) params.append('sort_order', options.sort_order)

    // Add filter parameters (simplified - would need full implementation)
    if (options.filter_criteria?.agent_id) {
      params.append('agent_id', options.filter_criteria.agent_id)
    }

    return `${baseUrl}?${params.toString()}`
  }

  private async getCachedChatData(_cacheKey: string): Promise<CachedChatData | null> {
    // This would integrate with optimizedApiService's cache
    // For now, return null to skip cache
    return null
  }

  private async setCachedChatData(_cacheKey: string, _data: CachedChatData): Promise<void> {
    // This would integrate with optimizedApiService's cache
    // Implementation would store the data with appropriate TTL
  }

  private processDeltaChanges(newChats: Chat[]): void {
    const now = Date.now()

    newChats.forEach(chat => {
      const chatHash = this.calculateChatHash(chat)
      const existingHash = this.changeTracker.chatHashes.get(chat.chat_id)

      if (!existingHash || existingHash !== chatHash) {
        console.log(`[OptimizedChatService] Chat ${chat.chat_id} has changes`)
        this.changeTracker.chatHashes.set(chat.chat_id, chatHash)
      }

      this.changeTracker.knownChatIds.add(chat.chat_id)
    })

    this.changeTracker.lastPollTime = now
  }

  private updateChangeTracker(chats: Chat[]): void {
    const now = Date.now()

    chats.forEach(chat => {
      const chatHash = this.calculateChatHash(chat)
      this.changeTracker.chatHashes.set(chat.chat_id, chatHash)
      this.changeTracker.knownChatIds.add(chat.chat_id)
    })

    this.changeTracker.lastPollTime = now
  }

  private calculateChatHash(chat: Chat): string {
    // Create a hash of key chat properties that might change
    const hashData = {
      status: chat.chat_status,
      endTime: chat.end_timestamp,
      messageCount: chat.message_with_tool_calls?.length || 0,
      lastMessage: chat.message_with_tool_calls?.slice(-1)[0]?.content || ''
    }
    return btoa(JSON.stringify(hashData))
  }
}

// Export singleton instance
export const optimizedChatService = new OptimizedChatService()